{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Efficient Net Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "NUM_CLASSES = 20\n",
    "NUM_FILTERS = 512\n",
    "OUTPUT_DIM = NUM_CLASSES + 5*B\n",
    "H, W = 224, 224\n",
    "SPLIT_SIZE = H//32\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_LoadDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None))>\n",
      "<_LoadDataset element_spec=(TensorSpec(shape=(224, 224, None), dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "trainDataset = tf.data.Dataset.load('SavedDataset/trainDataset')\n",
    "valDataset = tf.data.Dataset.load('SavedDataset/valDataset')\n",
    "print(trainDataset)\n",
    "print(valDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7, 7, 25), dtype=tf.float32, name=None))>\n",
      "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 7, 7, 25), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "trainDataset = trainDataset.map(lambda x, y: (\n",
    "    tf.ensure_shape(x, [224, 224, 3]),  # Ensure 3 channels (RGB)\n",
    "    tf.ensure_shape(y, [7, 7, NUM_CLASSES + 5])  # Ensure labels are correctly shaped\n",
    "))\n",
    "valDataset = valDataset.map(lambda x, y: (\n",
    "    tf.ensure_shape(x, [224, 224, 3]),\n",
    "    tf.ensure_shape(y, [7, 7, NUM_CLASSES + 5])\n",
    "))\n",
    "\n",
    "trainDataset = trainDataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "valDataset = valDataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(trainDataset)\n",
    "print(valDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('Models/YoloEfficientNetUntrained.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,575,239</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,898,752</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">12,845,568</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1470</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">754,110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ efficientnetb1 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     │     \u001b[38;5;34m6,575,239\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m5,898,752\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_38 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_39 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_40 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_41 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m12,845,568\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ leaky_re_lu_42 (\u001b[38;5;33mLeakyReLU\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1470\u001b[0m)           │       \u001b[38;5;34m754,110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_9 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m30\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,161,285</span> (126.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,161,285\u001b[0m (126.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,581,950</span> (101.40 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,581,950\u001b[0m (101.40 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,579,335</span> (25.10 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m6,579,335\u001b[0m (25.10 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YOLO Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIOU(boxes1, boxes2): # Intersection over Union\n",
    "    # Extract coordinates as xMin, yMin, xMax, yMax from xCenter, yCenter, width, height\n",
    "    boxes1 = tf.stack([boxes1[..., 0] - boxes1[..., 2] / 2.0,\n",
    "                       boxes1[..., 1] - boxes1[..., 3] / 2.0,\n",
    "                       boxes1[..., 0] + boxes1[..., 2] / 2.0,\n",
    "                       boxes1[..., 1] + boxes1[..., 3] / 2.0], axis=-1)\n",
    "    boxes2 = tf.stack([boxes2[..., 0] - boxes2[..., 2] / 2.0,\n",
    "                          boxes2[..., 1] - boxes2[..., 3] / 2.0,\n",
    "                          boxes2[..., 0] + boxes2[..., 2] / 2.0,\n",
    "                          boxes2[..., 1] + boxes2[..., 3] / 2.0], axis=-1)\n",
    "    \n",
    "    # Calculate intersection coordinates\n",
    "    lu = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    rd = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    # Calculate intersection area\n",
    "    intersection = tf.maximum(0.0, rd - lu)\n",
    "    intersectionArea = intersection[..., 0] * intersection[..., 1] # W * H\n",
    "\n",
    "    # Calculate union area\n",
    "    boxes1Area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2Area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "    unionArea = tf.maximum(boxes1Area + boxes2Area - intersectionArea, 1e-10)\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = intersectionArea / unionArea\n",
    "\n",
    "    return tf.clip_by_value(iou, 0.0, 1.0)\n",
    "\n",
    "    \n",
    "def yoloLoss(yTrue, yPred):\n",
    "    target = yTrue[..., 0] # Gets a tensor shape(7, 7, ) with first elements of each row, i.e, 1 or 0\n",
    "\n",
    "    ##### Objectness Loss #####\n",
    "    yPredExtract = tf.gather_nd(yPred, tf.where(target[:] == 1)) # Gets the predicted tensors where target is 1\n",
    "    yTrueExtract = tf.gather_nd(yTrue, tf.where(target[:] == 1)) # Gets the true tensors where target is 1\n",
    "\n",
    "    rescaler = tf.where(target[:] == 1)*SPLIT_SIZE # Gets the indices of the true tensors where target is 1 and multiplies by 7 to get New Origin with respect to the cell\n",
    "    upscaler1 = tf.concat([rescaler[:, 1:], tf.zeros([tf.shape(rescaler)[0], 2], dtype=tf.int64)], axis=-1) # Removes batch dimension and adds 0s to the end for width and height    \n",
    "    \n",
    "    # Gets the tensors and multiplies values by 32, 32, 224, 224 to get correct centres, with respect to cell origin & height and width with respect to image\n",
    "    targetUpscaler2 = tf.repeat([[32.,32.,224.,224.]],repeats=[tf.shape(rescaler)[0]], axis=0)*tf.cast(yTrueExtract[...,1:5], dtype = tf.float32)\n",
    "    pred1Upscaler2 = tf.repeat([[32.,32.,224.,224.]],repeats=[tf.shape(rescaler)[0]], axis=0)*tf.cast(yPredExtract[...,1:5], dtype = tf.float32)\n",
    "    pred2Upscaler2 = tf.repeat([[32.,32.,224.,224.]],repeats=[tf.shape(rescaler)[0]], axis=0)*tf.cast(yPredExtract[...,6:10], dtype = tf.float32)\n",
    "    \n",
    "    # Gets the original tensors with respect to the image\n",
    "    targetOriginal = tf.cast(upscaler1, dtype=tf.float32) + targetUpscaler2\n",
    "    pred1Original = tf.cast(upscaler1, dtype=tf.float32) + pred1Upscaler2\n",
    "    pred2Original = tf.cast(upscaler1, dtype=tf.float32) + pred2Upscaler2\n",
    "\n",
    "    # Calculates the IoU of the predicted and true tensors & choose the correct box to find object in -> outputs [0, 1] / [1, 0]\n",
    "    mask = tf.cast(tf.math.greater(computeIOU(pred1Original, targetOriginal), computeIOU(pred2Original, targetOriginal)), dtype=tf.int32)\n",
    "\n",
    "    # Choosing the correct box\n",
    "    yPredJoined = tf.transpose(tf.concat([tf.expand_dims(yPredExtract[..., 0], axis=0), tf.expand_dims(yPredExtract[..., 5], axis=0)], axis=0))\n",
    "    objPrediction = tf.gather_nd(yPredJoined, tf.stack([tf.range(tf.shape(rescaler)[0]), mask], axis=-1))\n",
    "\n",
    "    # Objectness Loss\n",
    "    objLoss = tf.reduce_sum(tf.square(tf.cast(tf.ones([tf.shape(rescaler)[0]]), dtype=tf.float32) - tf.cast(objPrediction, dtype=tf.float32)))\n",
    "\n",
    "    ##### Non-Objectness Loss ##### \n",
    "    yPredExtract = tf.gather_nd(yPred[..., 0:B*5], tf.where(target[:] == 0)) # Gets the predicted tensors where target is 0\n",
    "    yTrueExtract = tf.zeros(tf.shape(yPredExtract)[0])\n",
    "\n",
    "    noObjectLoss1 = tf.reduce_sum(tf.square(tf.cast(yTrueExtract, dtype=tf.float32) - tf.cast(yPredExtract[..., 0], dtype=tf.float32)))\n",
    "    noObjectLoss2 = tf.reduce_sum(tf.square(tf.cast(yTrueExtract, dtype=tf.float32) - tf.cast(yPredExtract[..., 5], dtype=tf.float32)))\n",
    "\n",
    "    noObjectLoss = noObjectLoss1 + noObjectLoss2\n",
    "\n",
    "    ##### Class Loss #####\n",
    "    yPredExtract = tf.gather_nd(yPred[..., 10:], tf.where(target[:] == 1)) # Gets the predicted tensors where target is 1\n",
    "    yTrueExtract = tf.gather_nd(yTrue[..., 5:], tf.where(target[:] == 1)) # Gets the true tensors where target is 1\n",
    "\n",
    "    classLoss = tf.reduce_sum(tf.square(tf.cast(yTrueExtract, dtype=tf.float32) - tf.cast(yPredExtract, dtype=tf.float32)))\n",
    "\n",
    "    ##### Box Loss #####\n",
    "    # Centre Loss\n",
    "    yPredExtract = tf.gather_nd(yPred[..., 0:5*B], tf.where(target[:] == 1)) # Gets the predicted tensors where target is 1\n",
    "    centreJoined = tf.stack([yPredExtract[..., 1:3], yPredExtract[..., 6:8]], axis=1)\n",
    "\n",
    "    centrePred = tf.gather_nd(centreJoined, tf.stack([tf.range(tf.shape(rescaler)[0]), mask], axis=-1))\n",
    "    centreTrue = tf.gather_nd(yTrue[..., 1:3], tf.where(target[:] == 1))\n",
    "\n",
    "    centreLoss = tf.reduce_sum(tf.square(tf.cast(centreTrue, dtype=tf.float32) - tf.cast(centrePred, dtype=tf.float32)))\n",
    "\n",
    "    # Size Loss\n",
    "    sizeJoined = tf.stack([yPredExtract[..., 3:5], yPredExtract[..., 8:10]], axis=1)\n",
    "\n",
    "    sizePred = tf.gather_nd(sizeJoined, tf.stack([tf.range(tf.shape(rescaler)[0]), mask], axis=-1))\n",
    "    sizeTrue = tf.gather_nd(yTrue[..., 3:5], tf.where(target[:] == 1))\n",
    "\n",
    "    sizeLoss = tf.reduce_sum(tf.square(tf.cast(tf.sqrt(tf.abs(sizeTrue)), dtype=tf.float32) - tf.cast(tf.sqrt(tf.abs(sizePred)), dtype=tf.float32)))\n",
    "\n",
    "    # Total Box Loss\n",
    "    boxLoss = centreLoss + sizeLoss\n",
    "\n",
    "    ##### Total Loss #####\n",
    "    lambdaCoord = 5\n",
    "    lambdaNoObj = 0.5\n",
    "    totalLoss = objLoss + lambdaNoObj*noObjectLoss + lambdaCoord*boxLoss + classLoss\n",
    "    return totalLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'Models/checkpoints/YoloEfficientNet.keras'\n",
    "modelCheckpointCallback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 40:\n",
    "        return 1e-3\n",
    "    elif epoch>=40 and epoch<80:\n",
    "        return 5e-4\n",
    "    else:\n",
    "        return 1e-4\n",
    "learningRateCallback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile & Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=yoloLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 289ms/step - loss: 272.1904 - val_loss: 206.0511 - learning_rate: 0.0010\n",
      "Epoch 2/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 235ms/step - loss: 174.6718 - val_loss: 184.2780 - learning_rate: 0.0010\n",
      "Epoch 3/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 233ms/step - loss: 159.9105 - val_loss: 178.2578 - learning_rate: 0.0010\n",
      "Epoch 4/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 235ms/step - loss: 150.0510 - val_loss: 169.0949 - learning_rate: 0.0010\n",
      "Epoch 5/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 251ms/step - loss: 140.9000 - val_loss: 166.5185 - learning_rate: 0.0010\n",
      "Epoch 6/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 234ms/step - loss: 132.9558 - val_loss: 161.8071 - learning_rate: 0.0010\n",
      "Epoch 7/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 235ms/step - loss: 125.5745 - val_loss: 160.9096 - learning_rate: 0.0010\n",
      "Epoch 8/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 231ms/step - loss: 118.5706 - val_loss: 158.0808 - learning_rate: 0.0010\n",
      "Epoch 9/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 111.6720 - val_loss: 157.1443 - learning_rate: 0.0010\n",
      "Epoch 10/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 222ms/step - loss: 105.6386 - val_loss: 159.9421 - learning_rate: 0.0010\n",
      "Epoch 11/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 100.0356 - val_loss: 155.5672 - learning_rate: 0.0010\n",
      "Epoch 12/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 228ms/step - loss: 94.5950 - val_loss: 155.5173 - learning_rate: 0.0010\n",
      "Epoch 13/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 89.7487 - val_loss: 152.8359 - learning_rate: 0.0010\n",
      "Epoch 14/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 85.8693 - val_loss: 151.1794 - learning_rate: 0.0010\n",
      "Epoch 15/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 82.1963 - val_loss: 155.2846 - learning_rate: 0.0010\n",
      "Epoch 16/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 78.6129 - val_loss: 152.3994 - learning_rate: 0.0010\n",
      "Epoch 17/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 226ms/step - loss: 75.1517 - val_loss: 150.8996 - learning_rate: 0.0010\n",
      "Epoch 18/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 71.7929 - val_loss: 153.2970 - learning_rate: 0.0010\n",
      "Epoch 19/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 227ms/step - loss: 69.6903 - val_loss: 150.4355 - learning_rate: 0.0010\n",
      "Epoch 20/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 66.8503 - val_loss: 149.8354 - learning_rate: 0.0010\n",
      "Epoch 21/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 226ms/step - loss: 64.8566 - val_loss: 151.2807 - learning_rate: 0.0010\n",
      "Epoch 22/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 62.5660 - val_loss: 152.2168 - learning_rate: 0.0010\n",
      "Epoch 23/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 60.2402 - val_loss: 154.0691 - learning_rate: 0.0010\n",
      "Epoch 24/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 222ms/step - loss: 58.5706 - val_loss: 150.4262 - learning_rate: 0.0010\n",
      "Epoch 25/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 56.8464 - val_loss: 153.0277 - learning_rate: 0.0010\n",
      "Epoch 26/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 55.0943 - val_loss: 153.2387 - learning_rate: 0.0010\n",
      "Epoch 27/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 53.8534 - val_loss: 154.7921 - learning_rate: 0.0010\n",
      "Epoch 28/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 52.4599 - val_loss: 157.0677 - learning_rate: 0.0010\n",
      "Epoch 29/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 50.6974 - val_loss: 154.8115 - learning_rate: 0.0010\n",
      "Epoch 30/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 49.5176 - val_loss: 153.8249 - learning_rate: 0.0010\n",
      "Epoch 31/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 48.4684 - val_loss: 158.3143 - learning_rate: 0.0010\n",
      "Epoch 32/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 229ms/step - loss: 47.4696 - val_loss: 152.5745 - learning_rate: 0.0010\n",
      "Epoch 33/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 219ms/step - loss: 46.4100 - val_loss: 155.7569 - learning_rate: 0.0010\n",
      "Epoch 34/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 218ms/step - loss: 45.4905 - val_loss: 154.2574 - learning_rate: 0.0010\n",
      "Epoch 35/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 218ms/step - loss: 44.4061 - val_loss: 154.3118 - learning_rate: 0.0010\n",
      "Epoch 36/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 219ms/step - loss: 43.3888 - val_loss: 155.6632 - learning_rate: 0.0010\n",
      "Epoch 37/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 221ms/step - loss: 42.1845 - val_loss: 153.6204 - learning_rate: 0.0010\n",
      "Epoch 38/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 227ms/step - loss: 41.7976 - val_loss: 152.4693 - learning_rate: 0.0010\n",
      "Epoch 39/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 232ms/step - loss: 40.7988 - val_loss: 153.9207 - learning_rate: 0.0010\n",
      "Epoch 40/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 235ms/step - loss: 39.9557 - val_loss: 156.1101 - learning_rate: 0.0010\n",
      "Epoch 41/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 237ms/step - loss: 37.8210 - val_loss: 151.6390 - learning_rate: 5.0000e-04\n",
      "Epoch 42/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 242ms/step - loss: 34.1674 - val_loss: 148.9749 - learning_rate: 5.0000e-04\n",
      "Epoch 43/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 249ms/step - loss: 32.5520 - val_loss: 152.6827 - learning_rate: 5.0000e-04\n",
      "Epoch 44/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 250ms/step - loss: 31.7103 - val_loss: 151.4310 - learning_rate: 5.0000e-04\n",
      "Epoch 45/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 294ms/step - loss: 31.2015 - val_loss: 149.8952 - learning_rate: 5.0000e-04\n",
      "Epoch 46/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 533ms/step - loss: 30.3341 - val_loss: 149.9967 - learning_rate: 5.0000e-04\n",
      "Epoch 47/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 237ms/step - loss: 30.0053 - val_loss: 148.5328 - learning_rate: 5.0000e-04\n",
      "Epoch 48/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 232ms/step - loss: 29.4973 - val_loss: 150.6372 - learning_rate: 5.0000e-04\n",
      "Epoch 49/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 231ms/step - loss: 29.0518 - val_loss: 153.2706 - learning_rate: 5.0000e-04\n",
      "Epoch 50/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 235ms/step - loss: 28.6396 - val_loss: 152.0523 - learning_rate: 5.0000e-04\n",
      "Epoch 51/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 229ms/step - loss: 28.3092 - val_loss: 152.7658 - learning_rate: 5.0000e-04\n",
      "Epoch 52/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 27.7017 - val_loss: 151.0963 - learning_rate: 5.0000e-04\n",
      "Epoch 53/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 241ms/step - loss: 27.2783 - val_loss: 151.6332 - learning_rate: 5.0000e-04\n",
      "Epoch 54/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 251ms/step - loss: 27.3461 - val_loss: 153.4353 - learning_rate: 5.0000e-04\n",
      "Epoch 55/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 249ms/step - loss: 26.7612 - val_loss: 153.9139 - learning_rate: 5.0000e-04\n",
      "Epoch 56/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 246ms/step - loss: 26.3880 - val_loss: 153.6116 - learning_rate: 5.0000e-04\n",
      "Epoch 57/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 252ms/step - loss: 26.2744 - val_loss: 152.2042 - learning_rate: 5.0000e-04\n",
      "Epoch 58/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 248ms/step - loss: 26.2818 - val_loss: 150.7070 - learning_rate: 5.0000e-04\n",
      "Epoch 59/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 253ms/step - loss: 25.6384 - val_loss: 150.3340 - learning_rate: 5.0000e-04\n",
      "Epoch 60/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 251ms/step - loss: 25.4382 - val_loss: 151.7143 - learning_rate: 5.0000e-04\n",
      "Epoch 61/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 256ms/step - loss: 25.1312 - val_loss: 152.0475 - learning_rate: 5.0000e-04\n",
      "Epoch 62/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 255ms/step - loss: 24.8201 - val_loss: 151.0908 - learning_rate: 5.0000e-04\n",
      "Epoch 63/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 254ms/step - loss: 24.6539 - val_loss: 149.5870 - learning_rate: 5.0000e-04\n",
      "Epoch 64/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 242ms/step - loss: 24.4592 - val_loss: 147.9221 - learning_rate: 5.0000e-04\n",
      "Epoch 65/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 241ms/step - loss: 24.4519 - val_loss: 150.7749 - learning_rate: 5.0000e-04\n",
      "Epoch 66/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 236ms/step - loss: 24.3583 - val_loss: 147.7049 - learning_rate: 5.0000e-04\n",
      "Epoch 67/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 242ms/step - loss: 23.9818 - val_loss: 149.5618 - learning_rate: 5.0000e-04\n",
      "Epoch 68/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 230ms/step - loss: 23.6278 - val_loss: 148.7582 - learning_rate: 5.0000e-04\n",
      "Epoch 69/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 242ms/step - loss: 23.3283 - val_loss: 150.6021 - learning_rate: 5.0000e-04\n",
      "Epoch 70/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 245ms/step - loss: 23.2413 - val_loss: 148.8516 - learning_rate: 5.0000e-04\n",
      "Epoch 71/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 239ms/step - loss: 23.1824 - val_loss: 149.4357 - learning_rate: 5.0000e-04\n",
      "Epoch 72/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 239ms/step - loss: 22.7104 - val_loss: 151.7019 - learning_rate: 5.0000e-04\n",
      "Epoch 73/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 233ms/step - loss: 22.7847 - val_loss: 153.0939 - learning_rate: 5.0000e-04\n",
      "Epoch 74/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 241ms/step - loss: 22.7443 - val_loss: 153.7514 - learning_rate: 5.0000e-04\n",
      "Epoch 75/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 240ms/step - loss: 22.6054 - val_loss: 151.8632 - learning_rate: 5.0000e-04\n",
      "Epoch 76/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 240ms/step - loss: 22.0695 - val_loss: 152.5489 - learning_rate: 5.0000e-04\n",
      "Epoch 77/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 246ms/step - loss: 22.1014 - val_loss: 156.0032 - learning_rate: 5.0000e-04\n",
      "Epoch 78/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 241ms/step - loss: 22.0412 - val_loss: 154.7972 - learning_rate: 5.0000e-04\n",
      "Epoch 79/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 229ms/step - loss: 21.6576 - val_loss: 152.8683 - learning_rate: 5.0000e-04\n",
      "Epoch 80/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 228ms/step - loss: 21.6498 - val_loss: 152.8760 - learning_rate: 5.0000e-04\n",
      "Epoch 81/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 233ms/step - loss: 21.0447 - val_loss: 152.0322 - learning_rate: 1.0000e-04\n",
      "Epoch 82/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 237ms/step - loss: 20.0720 - val_loss: 152.2386 - learning_rate: 1.0000e-04\n",
      "Epoch 83/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 237ms/step - loss: 19.5858 - val_loss: 151.1469 - learning_rate: 1.0000e-04\n",
      "Epoch 84/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 238ms/step - loss: 19.0331 - val_loss: 150.0025 - learning_rate: 1.0000e-04\n",
      "Epoch 85/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 241ms/step - loss: 18.5679 - val_loss: 150.6955 - learning_rate: 1.0000e-04\n",
      "Epoch 86/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 238ms/step - loss: 18.6469 - val_loss: 149.9262 - learning_rate: 1.0000e-04\n",
      "Epoch 87/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 234ms/step - loss: 18.4438 - val_loss: 150.1671 - learning_rate: 1.0000e-04\n",
      "Epoch 88/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 224ms/step - loss: 18.1396 - val_loss: 150.5373 - learning_rate: 1.0000e-04\n",
      "Epoch 89/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 17.9023 - val_loss: 150.6421 - learning_rate: 1.0000e-04\n",
      "Epoch 90/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 233ms/step - loss: 17.7082 - val_loss: 150.3937 - learning_rate: 1.0000e-04\n",
      "Epoch 91/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 229ms/step - loss: 17.6727 - val_loss: 150.5609 - learning_rate: 1.0000e-04\n",
      "Epoch 92/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 227ms/step - loss: 17.4526 - val_loss: 149.6773 - learning_rate: 1.0000e-04\n",
      "Epoch 93/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 226ms/step - loss: 17.5235 - val_loss: 149.6638 - learning_rate: 1.0000e-04\n",
      "Epoch 94/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 17.2774 - val_loss: 149.4060 - learning_rate: 1.0000e-04\n",
      "Epoch 95/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 17.3038 - val_loss: 148.8449 - learning_rate: 1.0000e-04\n",
      "Epoch 96/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 17.2222 - val_loss: 149.6088 - learning_rate: 1.0000e-04\n",
      "Epoch 97/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 226ms/step - loss: 17.1925 - val_loss: 149.3650 - learning_rate: 1.0000e-04\n",
      "Epoch 98/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 226ms/step - loss: 16.7143 - val_loss: 149.6502 - learning_rate: 1.0000e-04\n",
      "Epoch 99/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 16.7437 - val_loss: 149.8478 - learning_rate: 1.0000e-04\n",
      "Epoch 100/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 226ms/step - loss: 16.6681 - val_loss: 149.7038 - learning_rate: 1.0000e-04\n",
      "Epoch 101/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 16.6645 - val_loss: 149.8628 - learning_rate: 1.0000e-04\n",
      "Epoch 102/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 226ms/step - loss: 16.6710 - val_loss: 149.0664 - learning_rate: 1.0000e-04\n",
      "Epoch 103/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 225ms/step - loss: 16.7030 - val_loss: 149.6585 - learning_rate: 1.0000e-04\n",
      "Epoch 104/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 227ms/step - loss: 16.3685 - val_loss: 148.9507 - learning_rate: 1.0000e-04\n",
      "Epoch 105/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 229ms/step - loss: 16.2649 - val_loss: 149.6693 - learning_rate: 1.0000e-04\n",
      "Epoch 106/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 221ms/step - loss: 16.3125 - val_loss: 150.0125 - learning_rate: 1.0000e-04\n",
      "Epoch 107/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 222ms/step - loss: 16.4056 - val_loss: 149.6873 - learning_rate: 1.0000e-04\n",
      "Epoch 108/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 220ms/step - loss: 16.2761 - val_loss: 149.4416 - learning_rate: 1.0000e-04\n",
      "Epoch 109/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 219ms/step - loss: 16.0821 - val_loss: 148.7656 - learning_rate: 1.0000e-04\n",
      "Epoch 110/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 221ms/step - loss: 16.0967 - val_loss: 148.8739 - learning_rate: 1.0000e-04\n",
      "Epoch 111/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 221ms/step - loss: 16.0478 - val_loss: 149.0970 - learning_rate: 1.0000e-04\n",
      "Epoch 112/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 221ms/step - loss: 15.8036 - val_loss: 148.9877 - learning_rate: 1.0000e-04\n",
      "Epoch 113/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 222ms/step - loss: 15.8549 - val_loss: 149.2414 - learning_rate: 1.0000e-04\n",
      "Epoch 114/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 222ms/step - loss: 15.8734 - val_loss: 149.2533 - learning_rate: 1.0000e-04\n",
      "Epoch 115/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 222ms/step - loss: 15.7628 - val_loss: 148.9809 - learning_rate: 1.0000e-04\n",
      "Epoch 116/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 222ms/step - loss: 15.7145 - val_loss: 148.3005 - learning_rate: 1.0000e-04\n",
      "Epoch 117/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 15.9053 - val_loss: 149.5725 - learning_rate: 1.0000e-04\n",
      "Epoch 118/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 15.7424 - val_loss: 149.5863 - learning_rate: 1.0000e-04\n",
      "Epoch 119/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 15.7089 - val_loss: 149.2180 - learning_rate: 1.0000e-04\n",
      "Epoch 120/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 223ms/step - loss: 15.7381 - val_loss: 150.0321 - learning_rate: 1.0000e-04\n",
      "Epoch 121/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 218ms/step - loss: 15.7361 - val_loss: 149.0412 - learning_rate: 1.0000e-04\n",
      "Epoch 122/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 217ms/step - loss: 15.4061 - val_loss: 148.5258 - learning_rate: 1.0000e-04\n",
      "Epoch 123/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 220ms/step - loss: 15.4805 - val_loss: 149.8531 - learning_rate: 1.0000e-04\n",
      "Epoch 124/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 219ms/step - loss: 15.4068 - val_loss: 148.6628 - learning_rate: 1.0000e-04\n",
      "Epoch 125/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 221ms/step - loss: 15.2733 - val_loss: 149.9563 - learning_rate: 1.0000e-04\n",
      "Epoch 126/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 218ms/step - loss: 15.5123 - val_loss: 149.0906 - learning_rate: 1.0000e-04\n",
      "Epoch 127/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 218ms/step - loss: 15.4837 - val_loss: 148.8358 - learning_rate: 1.0000e-04\n",
      "Epoch 128/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 218ms/step - loss: 15.3439 - val_loss: 149.6472 - learning_rate: 1.0000e-04\n",
      "Epoch 129/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 218ms/step - loss: 15.2377 - val_loss: 149.2207 - learning_rate: 1.0000e-04\n",
      "Epoch 130/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 218ms/step - loss: 15.2556 - val_loss: 148.3318 - learning_rate: 1.0000e-04\n",
      "Epoch 131/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 220ms/step - loss: 15.0860 - val_loss: 148.5928 - learning_rate: 1.0000e-04\n",
      "Epoch 132/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 220ms/step - loss: 15.0726 - val_loss: 148.6342 - learning_rate: 1.0000e-04\n",
      "Epoch 133/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 219ms/step - loss: 15.0982 - val_loss: 148.8466 - learning_rate: 1.0000e-04\n",
      "Epoch 134/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 219ms/step - loss: 15.1024 - val_loss: 148.4203 - learning_rate: 1.0000e-04\n",
      "Epoch 135/135\n",
      "\u001b[1m534/534\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 221ms/step - loss: 15.0168 - val_loss: 148.9442 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    trainDataset,\n",
    "    validation_data=valDataset,\n",
    "    epochs=135,\n",
    "    verbose=1,\n",
    "    callbacks=[modelCheckpointCallback, learningRateCallback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
