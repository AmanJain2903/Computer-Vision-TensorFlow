{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINE TUNING PRE-TRAINED MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6799 files belonging to 3 classes.\n",
      "Using 5440 files for training.\n",
      "Found 6799 files belonging to 3 classes.\n",
      "Using 1359 files for validation.\n",
      "Found 2278 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 15:04:44.145343: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2025-01-30 15:04:44.145367: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2025-01-30 15:04:44.145375: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2025-01-30 15:04:44.145388: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-30 15:04:44.145398: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "CONFIGURATION = {\n",
    "    \"CLASS_NAMES\" : ['angry', 'happy', 'sad'],\n",
    "    \"BATCH_SIZE\" : 32,\n",
    "    \"IMAGE_SIZE\" : 256,\n",
    "    \"LEARNING_RATE\" : 0.01,\n",
    "    \"N_EPOCHS\" : 20,\n",
    "    \"DROPOUT_RATE\": 0.0,\n",
    "    \"REGULARIZATION_RATE\" : 0.0,\n",
    "    \"N_FILTERS\" : 6,\n",
    "    \"KERNEL_SIZE\" : 3,\n",
    "    \"N_STRIDES\" : 1,\n",
    "    \"POOL_SIZE\" : 2,\n",
    "    \"N_DENSE_1\" : 1024,\n",
    "    \"N_DENSE_2\" : 128,\n",
    "    \"NUM_CLASSES\" : 3\n",
    "}\n",
    "\n",
    "trainDirectory = \"/Users/aman/Documents/Work/Machine Learning/Computer-Vision-TensorFlow/Human-Emotions-Detection/Dataset/Emotions Dataset/Emotions Dataset/train\"\n",
    "testDirectory = \"/Users/aman/Documents/Work/Machine Learning/Computer-Vision-TensorFlow/Human-Emotions-Detection/Dataset/Emotions Dataset/Emotions Dataset/test\"\n",
    "\n",
    "trainDataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    trainDirectory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=CONFIGURATION[\"CLASS_NAMES\"],\n",
    "    color_mode='rgb',\n",
    "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
    "    image_size=(CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"]),\n",
    "    shuffle=True,\n",
    "    seed=99,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    ")\n",
    "\n",
    "valDataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    trainDirectory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=CONFIGURATION[\"CLASS_NAMES\"],\n",
    "    color_mode='rgb',\n",
    "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
    "    image_size=(CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"]),\n",
    "    shuffle=True,\n",
    "    seed=99,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    ")\n",
    "\n",
    "testDataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    testDirectory,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=CONFIGURATION[\"CLASS_NAMES\"],\n",
    "    color_mode='rgb',\n",
    "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
    "    image_size=(CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"]),\n",
    "    shuffle=True,\n",
    "    seed=99,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    ")\n",
    "\n",
    "trainDataset = trainDataset.prefetch(tf.data.AUTOTUNE)\n",
    "testDataset = testDataset.prefetch(tf.data.AUTOTUNE)\n",
    "valDataset = valDataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Pre-Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Pre-Trained Efficient Net B4 Model trained on ImageNet Dataset\n",
    "backbone = tf.keras.applications.EfficientNetB4(\n",
    "    include_top = False, # Include Classifier or Not\n",
    "    weights = 'imagenet',\n",
    "    input_shape = (CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"], 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Classification Model Using Pre-Trained Model as Feature Extractor Using Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Without Updating Pre-Trained Paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">17,673,823</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1792</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,836,032</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_15 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ efficientnetb4 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1792\u001b[0m)     │    \u001b[38;5;34m17,673,823\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1792\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,836,032\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m131,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,645,538</span> (74.94 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,645,538\u001b[0m (74.94 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,969,667</span> (7.51 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,969,667\u001b[0m (7.51 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,675,871</span> (67.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17,675,871\u001b[0m (67.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = tf.keras.layers.Input((CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"], 3))\n",
    "\n",
    "x = backbone(input, training = False)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(CONFIGURATION['N_DENSE_1'], activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dense(CONFIGURATION['N_DENSE_2'], activation='relu')(x)\n",
    "output = tf.keras.layers.Dense(CONFIGURATION['NUM_CLASSES'], activation='softmax')(x)\n",
    " \n",
    "fineTunedModel = tf.keras.models.Model(input, output)\n",
    "\n",
    "fineTunedModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = tf.keras.losses.CategoricalCrossentropy()\n",
    "METRICS = [tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\"), tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"top_k_accuracy\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTunedModel.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIGURATION[\"LEARNING_RATE\"]),\n",
    "    loss = lossFunction,\n",
    "    metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 15:24:06.470031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2s/step - accuracy: 0.4915 - loss: 6.2065 - top_k_accuracy: 0.8218 - val_accuracy: 0.5040 - val_loss: 21.7150 - val_top_k_accuracy: 0.7557\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5912 - loss: 5.3536 - top_k_accuracy: 0.8587 - val_accuracy: 0.4650 - val_loss: 22.1155 - val_top_k_accuracy: 0.8190\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6557 - loss: 1.6768 - top_k_accuracy: 0.9340 - val_accuracy: 0.3319 - val_loss: 16.8002 - val_top_k_accuracy: 0.7469\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6557 - loss: 2.4237 - top_k_accuracy: 0.8773 - val_accuracy: 0.3650 - val_loss: 9.4549 - val_top_k_accuracy: 0.6519\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6789 - loss: 1.6233 - top_k_accuracy: 0.9064 - val_accuracy: 0.5011 - val_loss: 10.6160 - val_top_k_accuracy: 0.8124\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7248 - loss: 1.4812 - top_k_accuracy: 0.9078 - val_accuracy: 0.4614 - val_loss: 4.5613 - val_top_k_accuracy: 0.8094\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6745 - loss: 1.7413 - top_k_accuracy: 0.9133 - val_accuracy: 0.6181 - val_loss: 4.2673 - val_top_k_accuracy: 0.8587\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7597 - loss: 1.8284 - top_k_accuracy: 0.9309 - val_accuracy: 0.6358 - val_loss: 3.2802 - val_top_k_accuracy: 0.8675\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7214 - loss: 1.4917 - top_k_accuracy: 0.9169 - val_accuracy: 0.5997 - val_loss: 3.6911 - val_top_k_accuracy: 0.8286\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7744 - loss: 1.0500 - top_k_accuracy: 0.9304 - val_accuracy: 0.6130 - val_loss: 4.4669 - val_top_k_accuracy: 0.8756\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8149 - loss: 1.2079 - top_k_accuracy: 0.9337 - val_accuracy: 0.6549 - val_loss: 3.1758 - val_top_k_accuracy: 0.8823\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7003 - loss: 1.6634 - top_k_accuracy: 0.9160 - val_accuracy: 0.5806 - val_loss: 4.4001 - val_top_k_accuracy: 0.8595\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7693 - loss: 1.3513 - top_k_accuracy: 0.9055 - val_accuracy: 0.6608 - val_loss: 2.8154 - val_top_k_accuracy: 0.8896\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7255 - loss: 1.9028 - top_k_accuracy: 0.9398 - val_accuracy: 0.6306 - val_loss: 3.8511 - val_top_k_accuracy: 0.8550\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6634 - loss: 4.4901 - top_k_accuracy: 0.9318 - val_accuracy: 0.5872 - val_loss: 11.4449 - val_top_k_accuracy: 0.7940\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7093 - loss: 4.8652 - top_k_accuracy: 0.8952 - val_accuracy: 0.5636 - val_loss: 9.8263 - val_top_k_accuracy: 0.7991\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.7734 - loss: 3.0901 - top_k_accuracy: 0.9341 - val_accuracy: 0.6512 - val_loss: 6.4129 - val_top_k_accuracy: 0.8536\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7470 - loss: 3.0479 - top_k_accuracy: 0.9050 - val_accuracy: 0.6012 - val_loss: 9.4124 - val_top_k_accuracy: 0.8742\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7456 - loss: 2.9501 - top_k_accuracy: 0.9301 - val_accuracy: 0.5975 - val_loss: 8.6617 - val_top_k_accuracy: 0.8617\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.7550 - loss: 3.7713 - top_k_accuracy: 0.9620 - val_accuracy: 0.5180 - val_loss: 15.3853 - val_top_k_accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "history = fineTunedModel.fit(\n",
    "    trainDataset.take(10), # Training on a small dataset\n",
    "    validation_data = valDataset,\n",
    "    epochs = CONFIGURATION['N_EPOCHS'],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training The Model Again But Now With Trainable for Backbone set to True & a very Small Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fineTunedModel.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=CONFIGURATION[\"LEARNING_RATE\"]/100),\n",
    "    loss = lossFunction,\n",
    "    metrics=METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 6s/step - accuracy: 0.5072 - loss: 21.3122 - top_k_accuracy: 0.7764 - val_accuracy: 0.5077 - val_loss: 12.8549 - val_top_k_accuracy: 0.7999\n",
      "Epoch 2/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4s/step - accuracy: 0.5529 - loss: 11.0458 - top_k_accuracy: 0.8274 - val_accuracy: 0.4915 - val_loss: 11.7590 - val_top_k_accuracy: 0.8197\n",
      "Epoch 3/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4s/step - accuracy: 0.5568 - loss: 6.8853 - top_k_accuracy: 0.8632 - val_accuracy: 0.4893 - val_loss: 11.3573 - val_top_k_accuracy: 0.8300\n",
      "Epoch 4/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 4s/step - accuracy: 0.6764 - loss: 3.8358 - top_k_accuracy: 0.9324 - val_accuracy: 0.4820 - val_loss: 11.5820 - val_top_k_accuracy: 0.8227\n",
      "Epoch 5/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5s/step - accuracy: 0.7610 - loss: 3.1444 - top_k_accuracy: 0.9540 - val_accuracy: 0.4687 - val_loss: 11.7297 - val_top_k_accuracy: 0.8153\n",
      "Epoch 6/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4s/step - accuracy: 0.7861 - loss: 2.3075 - top_k_accuracy: 0.9636 - val_accuracy: 0.4577 - val_loss: 12.0438 - val_top_k_accuracy: 0.8116\n",
      "Epoch 7/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.7167 - loss: 2.6747 - top_k_accuracy: 0.9601 - val_accuracy: 0.4408 - val_loss: 12.6541 - val_top_k_accuracy: 0.8006\n",
      "Epoch 8/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4s/step - accuracy: 0.7604 - loss: 2.6655 - top_k_accuracy: 0.9435 - val_accuracy: 0.4408 - val_loss: 12.8457 - val_top_k_accuracy: 0.7962\n",
      "Epoch 9/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.7741 - loss: 2.5025 - top_k_accuracy: 0.9645 - val_accuracy: 0.4400 - val_loss: 12.6527 - val_top_k_accuracy: 0.7896\n",
      "Epoch 10/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.7794 - loss: 1.9008 - top_k_accuracy: 0.9426 - val_accuracy: 0.4481 - val_loss: 12.5082 - val_top_k_accuracy: 0.7896\n",
      "Epoch 11/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 5s/step - accuracy: 0.7793 - loss: 1.9876 - top_k_accuracy: 0.9218 - val_accuracy: 0.4540 - val_loss: 12.1862 - val_top_k_accuracy: 0.7932\n",
      "Epoch 12/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5s/step - accuracy: 0.8288 - loss: 1.1358 - top_k_accuracy: 0.9727 - val_accuracy: 0.4547 - val_loss: 11.7878 - val_top_k_accuracy: 0.7954\n",
      "Epoch 13/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - accuracy: 0.8179 - loss: 1.6053 - top_k_accuracy: 0.9623 - val_accuracy: 0.4555 - val_loss: 11.5459 - val_top_k_accuracy: 0.7947\n",
      "Epoch 14/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 5s/step - accuracy: 0.8339 - loss: 1.3382 - top_k_accuracy: 0.9781 - val_accuracy: 0.4680 - val_loss: 11.1577 - val_top_k_accuracy: 0.7918\n",
      "Epoch 15/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 5s/step - accuracy: 0.8011 - loss: 1.1277 - top_k_accuracy: 0.9743 - val_accuracy: 0.4570 - val_loss: 11.1192 - val_top_k_accuracy: 0.7815\n",
      "Epoch 16/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 5s/step - accuracy: 0.8467 - loss: 1.0836 - top_k_accuracy: 0.9588 - val_accuracy: 0.4614 - val_loss: 10.8104 - val_top_k_accuracy: 0.7741\n",
      "Epoch 17/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 5s/step - accuracy: 0.8955 - loss: 0.7546 - top_k_accuracy: 0.9795 - val_accuracy: 0.4753 - val_loss: 10.1612 - val_top_k_accuracy: 0.7763\n",
      "Epoch 18/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 5s/step - accuracy: 0.8489 - loss: 1.1017 - top_k_accuracy: 0.9699 - val_accuracy: 0.4849 - val_loss: 9.8549 - val_top_k_accuracy: 0.7866\n",
      "Epoch 19/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4s/step - accuracy: 0.8526 - loss: 0.9718 - top_k_accuracy: 0.9784 - val_accuracy: 0.4974 - val_loss: 9.5922 - val_top_k_accuracy: 0.7940\n",
      "Epoch 20/20\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5s/step - accuracy: 0.8694 - loss: 0.8794 - top_k_accuracy: 0.9671 - val_accuracy: 0.5040 - val_loss: 9.2209 - val_top_k_accuracy: 0.7976\n"
     ]
    }
   ],
   "source": [
    "history = fineTunedModel.fit(\n",
    "    trainDataset.take(10), # Training on a small dataset\n",
    "    validation_data = valDataset,\n",
    "    epochs = CONFIGURATION['N_EPOCHS'],\n",
    "    verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
